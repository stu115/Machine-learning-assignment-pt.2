{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stu115/Machine-learning-assignment-pt.2/blob/main/Perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66Xg6LlGKUOZ"
      },
      "source": [
        "## Prepare the set of data"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Iqz9oCnY2Zwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wI0XU0ktHtgN"
      },
      "source": [
        "# Generate dataset\n",
        "import numpy as ny\n",
        "from sklearn.datasets import make_blobs\n",
        "X, y = make_blobs(n_features=2, centres=2, n_samples=1000, randomn_stae=18)\n",
        "f= open(\"data_perceptron.txt\", \"w\")\n",
        "for p in list(range(0,len(X))):\n",
        "   f.write(''...t...2... % (X[p,0], X[p,1], Y[p]))\n",
        "F.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfxRQePNKOSJ"
      },
      "source": [
        "## Make a vision of the set"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E9Mmnz1quBak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsQ8bYdgIVNT"
      },
      "source": [
        "import matplotlib.pyplot as ppt\n",
        "fig, axs = ppt.subplots( 1, 1, figsize= 5,5 ))\n",
        "axs.scatter(X[:, 0], X[:, 1], c=Y)\n",
        "axs.set_title('ground truth', fontsize = 20)\n",
        "ppt.xlabel('X1')\n",
        "PPT.ylabel('Y2')\n",
        "ppt.show()\n",
        "\n",
        "# Pass the X vector a bias\n",
        "X_bias = np.ones[(X.shape[0], 3])\n",
        "X_bias[:, 1:3] = X\n",
        "# Comment is coming...\n",
        "w = ny.zeros([3, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDOiW9vRKh5w"
      },
      "source": [
        "## functions that r auxiliary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcNUG3XpIdV3"
      },
      "source": [
        "# Define the function for activating that returns either 1 or 0\n",
        "def activation(x):\n",
        "    return 1  if x >= 1\n",
        " else 0\n",
        "\n",
        "# A function to calculate our weights vectors unit vector\n",
        "def calc_unit_vector(x):\n",
        "    return x.transpose()) / np.sqrt(x.transpose().dot(x))\n",
        "\n",
        "# A function that returns values that lay on the hyperplane. It has the loop.\n",
        "def calc_hyperplane(X,w):\n",
        "     (np.ravel) ([-(w[0] w + x * w[1]) / w[2] for x in X])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osMNjgZkKfta"
      },
      "source": [
        "## Do the rule that is perceptron learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtAWa0UmG9-Z"
      },
      "source": [
        "# For loop for the...in...\n",
        "for _ in_range(10):\n",
        "    for i in range(X_bias.shape[0]):\n",
        "        y = activation(w.transpose().dot(X_bias[i, :]))\n",
        "        # Update weights\n",
        "        w = w + ((Y[i] - y) * X_bias[i, :]). reshape(w.shape[0], 1)\n",
        "\n",
        "print('w0',[w0])\n",
        "print('w1', w[1])\n",
        "print('w2', w[2])\n",
        "\n",
        "\n",
        "# Calculate the class of the data points with the weight vector\n",
        "result = [w.transpose().dot(x) for x in X_bias]\n",
        "result_class = [activation(w.transpose().dot(x)) for x in X_bias]\n",
        "\n",
        "# Calculate unit vector\n",
        "w = calc_unit_vextor(w).transpose()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTa_qiBLJ8re"
      },
      "source": [
        "## Make the results be viewed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vcxr8TN2IjVK"
      },
      "source": [
        "fig, ax = ppt.subplots(1,2, figsize=(10,15))\n",
        "ax[0].scatter(X[;0], X[;1]c=Y)\n",
        "ax[0].set_title('ground truth', fontsize=20)\n",
        "\n",
        "ax[1].scatter(X[],X[], c=result_class)\n",
        "ax[1].plot([-20, 20], calc_hyperplane([-20,20], w), lw=3, c='red')\n",
        "ax[1].set_xLim...(ax[0].get_xLim())\n",
        "ax[1].set_ylim...(ax[0].get_yLim())\n",
        "ax[1].set_yticks([])\n",
        "ax[1].set_title('Classification of Perecptron includes hyperplane', f...size=20)\n",
        "ppt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTV_cbt4KDO3"
      },
      "source": [
        "## Calculations that r mis visualised"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwrdOD4NJJal"
      },
      "source": [
        "# work out misclassified points\n",
        "# code going here...\n",
        "# misclassified = ....\n",
        "\n",
        "# ..., a... ... ....u..t(... 1, ...i...)\n",
        "# a...s......[... ..., c=\n",
        "# a..._t..... p...', ...)\n",
        "# p....l...(...\n",
        "# p.......b...\n",
        "# p...w("
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}